{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from IncrementalTrainingApproach.iCaRL import iCaRLmodel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from models import get_feature_extractor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "feature_extractor = get_feature_extractor('vit_lite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = iCaRLmodel(10,feature_extractor,64,10,2000,10,0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<IncrementalTrainingApproach.iCaRL.iCaRLmodel object at 0x0000018DD3532F48>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "imgs = torch.randn((3,3,32,32))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "target = torch.tensor([1,2,3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the size of train set is (5000, 32, 32, 3)\n",
      "the size of train label is (5000,)\n",
      "the size of test set is (2000, 32, 32, 3)\n",
      "the size of test label is (2000,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_loader,test_loader = model._get_train_and_test_dataloader([0,10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_one_hot(target, num_class):\n",
    "    one_hot = torch.zeros(target.shape[0], num_class)\n",
    "    one_hot = one_hot.scatter(dim=1, index=target.long().view(-1, 1), value=1.)\n",
    "    return one_hot\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "new_target = get_one_hot(target,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "new_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "output = model.model(imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 10])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "return_val = F.binary_cross_entropy_with_logits(output,new_target)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor(0.7341, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(return_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model.numclass+=model.task_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "model.numclass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import copy\n",
    "model.old_model =  copy.deepcopy(model.model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "network(\n",
      "  (feature): ViTLite(\n",
      "    (tokenizer): Tokenizer(\n",
      "      (conv_layers): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(3, 512, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (1): Identity()\n",
      "          (2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (flattener): Flatten(start_dim=2, end_dim=3)\n",
      "    )\n",
      "    (classifier): Transformer(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (blocks): ModuleList(\n",
      "        (0): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (9): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (10): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (11): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (12): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (13): TransformerEncoder(\n",
      "          (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (self_attn): Attention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc): Identity()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(model.old_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "classes = [model.numclass-model.task_size, model.numclass]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[10, 20]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 39
    }
   ],
   "source": [
    "classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the size of train set is (5000, 32, 32, 3)\n",
      "the size of train label is (5000,)\n",
      "the size of test set is (3000, 32, 32, 3)\n",
      "the size of test label is (3000,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.train_loader,model.test_loader = model._get_train_and_test_dataloader(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "datas, labels = [],[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "target = torch.tensor([11,12,13])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "new_target = get_one_hot(target,model.numclass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n         0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n         0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n         0., 0.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "new_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "old_target = model.old_model(imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model.model.Incremental_learning(model.numclass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "output = model.model(imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([3, 20])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "old_target = torch.sigmoid(old_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 10])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 63
    }
   ],
   "source": [
    "old_target.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 20])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 64
    }
   ],
   "source": [
    "new_target.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 67
    }
   ],
   "source": [
    "old_task_size = old_target.shape[1]\n",
    "old_task_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "new_target[...,:old_task_size] = old_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5646, 0.4944, 0.6143, 0.5941, 0.7327, 0.5278, 0.6995, 0.3335, 0.3580,\n         0.4185, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000],\n        [0.5656, 0.5241, 0.6247, 0.5699, 0.7120, 0.5415, 0.7165, 0.3197, 0.3470,\n         0.4172, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000],\n        [0.5724, 0.5172, 0.6248, 0.6027, 0.7295, 0.5115, 0.7042, 0.3290, 0.3311,\n         0.4123, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000]], grad_fn=<CopySlices>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 75
    }
   ],
   "source": [
    "new_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.2599, -0.0225,  0.4655,  0.3810,  1.0083,  0.1112,  0.8450, -0.6922,\n         -0.5841, -0.3288, -0.0520,  0.9260,  0.3527,  0.4571, -0.3031,  0.1416,\n          0.0415, -0.4042,  0.3315, -1.1275],\n        [ 0.2638,  0.0966,  0.5096,  0.2816,  0.9053,  0.1665,  0.9271, -0.7552,\n         -0.6323, -0.3343, -0.1703,  0.9366,  0.3041,  0.3613, -0.3304,  0.2799,\n          0.0303, -0.4780,  0.4891, -0.9540],\n        [ 0.2918,  0.0687,  0.5101,  0.4167,  0.9923,  0.0461,  0.8672, -0.7126,\n         -0.7034, -0.3544, -0.0359,  0.9769,  0.3813,  0.4452, -0.2919,  0.1361,\n         -0.0561, -0.4883,  0.4845, -0.9265]], grad_fn=<AddmmBackward>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 78
    }
   ],
   "source": [
    "output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "bce = F.binary_cross_entropy_with_logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0387, -0.4745, -0.3007,  1.3920,  0.1990, -0.4828, -0.9736, -0.1006,\n         -0.6378,  1.0279],\n        [-1.0514,  0.6900,  1.7681,  0.7924, -1.1241,  1.4034,  0.9899,  0.1120,\n         -1.3201, -0.3777]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "test_output = torch.randn((2,10))\n",
    "test_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 86
    }
   ],
   "source": [
    "target = torch.tensor([2,5])\n",
    "target.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "loss_cross_entropy = cross_entropy(test_output,target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.2129)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 88
    }
   ],
   "source": [
    "loss_cross_entropy\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 89
    }
   ],
   "source": [
    "target_one_hot = get_one_hot(target,10)\n",
    "target_one_hot\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7735)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 91
    }
   ],
   "source": [
    "loss_bce = bce(test_output,target_one_hot)\n",
    "\n",
    "loss_bce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}